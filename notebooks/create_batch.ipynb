{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from azureml.core import Workspace\r\n",
    "ws = Workspace.from_config()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from azureml.core import Workspace\r\n",
    "ws = Workspace.from_config()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Provision compute context for the pipeline\r\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
    "from azureml.core.compute_target import ComputeTargetException\r\n",
    "\r\n",
    "cluster_name = \"mlopsbootcamp\"\r\n",
    "\r\n",
    "try:\r\n",
    "    # Check for existing compute target\r\n",
    "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
    "    print('Found existing cluster, use it.')\r\n",
    "except ComputeTargetException:\r\n",
    "    # If it doesn't already exist, create it\r\n",
    "    try:\r\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS2_v2', max_nodes=2)\r\n",
    "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
    "        inference_cluster.wait_for_completion(show_output=True)\r\n",
    "    except Exception as ex:\r\n",
    "        print(ex)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\r\n",
    "\r\n",
    "# Create a folder for the files\r\n",
    "capstone_folder = os.path.join(os.path.dirname(os.getcwd()),'pytown_energymonitor')\r\n",
    "print(capstone_folder)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Users\\meira\\Projects\\PyLadiesMLOpsCapstone\\pytown_energymonitor\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "%%writefile $capstone_folder\\score.py\r\n",
    "\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "def init():\r\n",
    "    # Runs when the pipeline step is initialized\r\n",
    "    global model\r\n",
    "\r\n",
    "def run(mini_batch):\r\n",
    "    # This runs for each batch\r\n",
    "    resultList = []\r\n",
    "\r\n",
    "    # process each file in the batch\r\n",
    "    for f in mini_batch:\r\n",
    "        # Read csv file into a dataframe\r\n",
    "        input_df = pd.read_csv(f)\r\n",
    "        # calculate naive forecast\r\n",
    "        prediction_df = (\r\n",
    "            input_df.groupby('dayofweek')\r\n",
    "            .rolling(3, closed = 'left')\r\n",
    "            .mean()\r\n",
    "            .reset_index()\r\n",
    "            .sort_values(by ='data_index_')\r\n",
    "            .set_index('data_index_')\r\n",
    "        ).rename(columns ={'load_actuals_mw' : 'load_pred_mw'})\r\n",
    "        # Append prediction to results\r\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction_df['load_pred_mw'].tail(7)))\r\n",
    "    return resultList"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting c:\\Users\\meira\\Projects\\PyLadiesMLOpsCapstone\\pytown_energymonitor\\score.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "%%writefile $capstone_folder\\capstone_environment.yml\r\n",
    "name: capstone_environment\r\n",
    "dependencies:\r\n",
    "- python=3.8\r\n",
    "- numpy\r\n",
    "- pandas\r\n",
    "- scikit-learn\r\n",
    "- pip:\r\n",
    "  - azureml-core"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting c:\\Users\\meira\\Projects\\PyLadiesMLOpsCapstone\\pytown_energymonitor\\capstone_environment.yml\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from azureml.core import Environment\r\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
    "\r\n",
    "# Create an Environment for the pipeline to run\r\n",
    "capstone_env = Environment.from_conda_specification(\"capstone_env\", capstone_folder + \"/capstone_environment.yml\")\r\n",
    "capstone_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
    "print('Configuration ready.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# run the batch pipeline: execute py script and save results to txt in the output folder\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\r\n",
    "from azureml.data import OutputFileDatasetConfig\r\n",
    "from azureml.core.runconfig import DockerConfiguration\r\n",
    "\r\n",
    "# # Get the batch dataset for input\r\n",
    "input_data_set = ws.datasets['daily_load_data']\r\n",
    "\r\n",
    "# Set the output location\r\n",
    "default_ds = ws.get_default_datastore()\r\n",
    "output_dir = OutputFileDatasetConfig(name='capstone_inferences')\r\n",
    "\r\n",
    "# Define the parallel run step step configuration\r\n",
    "parallel_run_config = ParallelRunConfig(\r\n",
    "    source_directory=capstone_folder,\r\n",
    "    entry_script=\"score.py\",\r\n",
    "    mini_batch_size=\"5\",\r\n",
    "    error_threshold=10,\r\n",
    "    output_action=\"append_row\",\r\n",
    "    environment=capstone_env,\r\n",
    "    compute_target=inference_cluster,\r\n",
    "    node_count=2)\r\n",
    "\r\n",
    "parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\r\n",
    "\r\n",
    "# Create the parallel run step\r\n",
    "parallelrun_step = ParallelRunStep(\r\n",
    "    name=parallel_step_name,\r\n",
    "    parallel_run_config=parallel_run_config,\r\n",
    "    inputs=[input_data_set.as_named_input('daily_load_data')],\r\n",
    "    output=output_dir,\r\n",
    "    arguments=[],\r\n",
    "    allow_reuse=True\r\n",
    ")\r\n",
    "\r\n",
    "print('Steps defined')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Steps defined\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\meira\\anaconda3\\envs\\capstone_mlops\\lib\\site-packages\\azureml\\pipeline\\core\\_parallel_run_step_base.py:580: UserWarning: \n",
      "ParallelRunStep requires azureml-dataset-runtime[fuse,pandas] for tabular dataset.\n",
      "Please add relevant package in CondaDependencies.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from azureml.core import Experiment\r\n",
    "from azureml.pipeline.core import Pipeline\r\n",
    "\r\n",
    "# Create the pipeline\r\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\r\n",
    "\r\n",
    "# Run the pipeline as an experiment\r\n",
    "pipeline_run = Experiment(ws, 'capstone-naive-forecast-batch').submit(pipeline)\r\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created step batchscoring-202108061705 [b14fe54d][2e60f393-2634-4fab-bec6-5d1e15e65ee3], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 4b4e9726-cd74-4e9d-8e31-35a9541bef2d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/4b4e9726-cd74-4e9d-8e31-35a9541bef2d?wsid=/subscriptions/3f708c1c-dec8-4886-90e0-6657d6b42467/resourcegroups/mlops_bootcamp/workspaces/mlops&tid=964d978b-aade-4afb-b035-7c91124668cf\n",
      "PipelineRunId: 4b4e9726-cd74-4e9d-8e31-35a9541bef2d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/4b4e9726-cd74-4e9d-8e31-35a9541bef2d?wsid=/subscriptions/3f708c1c-dec8-4886-90e0-6657d6b42467/resourcegroups/mlops_bootcamp/workspaces/mlops&tid=964d978b-aade-4afb-b035-7c91124668cf\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 77445767-8428-4d32-8141-4082802d063a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/77445767-8428-4d32-8141-4082802d063a?wsid=/subscriptions/3f708c1c-dec8-4886-90e0-6657d6b42467/resourcegroups/mlops_bootcamp/workspaces/mlops&tid=964d978b-aade-4afb-b035-7c91124668cf\n",
      "StepRun( batchscoring-202108061705 ) Status: NotStarted\n",
      "StepRun( batchscoring-202108061705 ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_62be58d12b386c05d8a84080a18418916d00ec65aff9e984fb6966efd3499283_d.txt\n",
      "========================================================================================================================\n",
      "2021-08-06T15:08:30Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/77445767-8428-4d32-8141-4082802d063a/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/77445767-8428-4d32-8141-4082802d063a/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=11461 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/77445767-8428-4d32-8141-4082802d063a/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-08-06T15:08:30Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/77445767-8428-4d32-8141-4082802d063a/mounts/workspaceblobstore\n",
      "2021-08-06T15:08:31Z The vmsize standard_ds2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-08-06T15:08:31Z Starting output-watcher...\n",
      "2021-08-06T15:08:31Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_37b71d944131a5da3ec055f8261503ea\n",
      "92473f7ef455: Pulling fs layer\n",
      "fb52bde70123: Pulling fs layer\n",
      "64788f86be3f: Pulling fs layer\n",
      "33f6d5f2e001: Pulling fs layer\n",
      "eeb715f1b6ae: Pulling fs layer\n",
      "fe519cf36537: Pulling fs layer\n",
      "58ff99196c15: Pulling fs layer\n",
      "9b13f06a8eff: Pulling fs layer\n",
      "2d4e93adbf58: Pulling fs layer\n",
      "6ee7c3767844: Pulling fs layer\n",
      "62cfc3ccb8ab: Pulling fs layer\n",
      "4a7af9d757ee: Pulling fs layer\n",
      "08594b643883: Pulling fs layer\n",
      "5d0f4c10c7b3: Pulling fs layer\n",
      "9087fc082d04: Pulling fs layer\n",
      "c4eced8bb9ef: Pulling fs layer\n",
      "e31a66accdee: Pulling fs layer\n",
      "0eecd57731f6: Pulling fs layer\n",
      "33f6d5f2e001: Waiting\n",
      "eeb715f1b6ae: Waiting\n",
      "fe519cf36537: Waiting\n",
      "58ff99196c15: Waiting\n",
      "9b13f06a8eff: Waiting\n",
      "2d4e93adbf58: Waiting\n",
      "6ee7c3767844: Waiting\n",
      "62cfc3ccb8ab: Waiting\n",
      "4a7af9d757ee: Waiting\n",
      "08594b643883: Waiting\n",
      "5d0f4c10c7b3: Waiting\n",
      "9087fc082d04: Waiting\n",
      "c4eced8bb9ef: Waiting\n",
      "e31a66accdee: Waiting\n",
      "0eecd57731f6: Waiting\n",
      "fb52bde70123: Verifying Checksum\n",
      "64788f86be3f: Verifying Checksum\n",
      "64788f86be3f: Download complete\n",
      "33f6d5f2e001: Verifying Checksum\n",
      "33f6d5f2e001: Download complete\n",
      "fe519cf36537: Verifying Checksum\n",
      "fe519cf36537: Download complete\n",
      "92473f7ef455: Verifying Checksum\n",
      "92473f7ef455: Download complete\n",
      "58ff99196c15: Verifying Checksum\n",
      "58ff99196c15: Download complete\n",
      "9b13f06a8eff: Verifying Checksum\n",
      "9b13f06a8eff: Download complete\n",
      "eeb715f1b6ae: Verifying Checksum\n",
      "eeb715f1b6ae: Download complete\n",
      "6ee7c3767844: Verifying Checksum\n",
      "6ee7c3767844: Download complete\n",
      "4a7af9d757ee: Verifying Checksum\n",
      "4a7af9d757ee: Download complete\n",
      "62cfc3ccb8ab: Verifying Checksum\n",
      "62cfc3ccb8ab: Download complete\n",
      "08594b643883: Verifying Checksum\n",
      "08594b643883: Download complete\n",
      "9087fc082d04: Verifying Checksum\n",
      "9087fc082d04: Download complete\n",
      "c4eced8bb9ef: Verifying Checksum\n",
      "c4eced8bb9ef: Download complete\n",
      "e31a66accdee: Verifying Checksum\n",
      "e31a66accdee: Download complete\n",
      "0eecd57731f6: Verifying Checksum\n",
      "0eecd57731f6: Download complete\n",
      "2d4e93adbf58: Verifying Checksum\n",
      "2d4e93adbf58: Download complete\n",
      "92473f7ef455: Pull complete\n",
      "fb52bde70123: Pull complete\n",
      "64788f86be3f: Pull complete\n",
      "33f6d5f2e001: Pull complete\n",
      "5d0f4c10c7b3: Verifying Checksum\n",
      "5d0f4c10c7b3: Download complete\n",
      "eeb715f1b6ae: Pull complete\n",
      "fe519cf36537: Pull complete\n",
      "58ff99196c15: Pull complete\n",
      "9b13f06a8eff: Pull complete\n",
      "2d4e93adbf58: Pull complete\n",
      "6ee7c3767844: Pull complete\n",
      "62cfc3ccb8ab: Pull complete\n",
      "4a7af9d757ee: Pull complete\n",
      "08594b643883: Pull complete\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_62be58d12b386c05d8a84080a18418916d00ec65aff9e984fb6966efd3499283_d.txt\n",
      "===============================================================================================================\n",
      "[2021-08-06T15:08:57.040080] Entering job preparation.\n",
      "[2021-08-06T15:08:57.570737] Starting job preparation.\n",
      "[2021-08-06T15:08:57.570766] Extracting the control code.\n",
      "[2021-08-06T15:08:57.571432] Starting extract_project.\n",
      "[2021-08-06T15:08:57.571503] Starting to extract zip file.\n",
      "[2021-08-06T15:08:57.594420] Finished extracting zip file.\n",
      "[2021-08-06T15:08:57.596989] Using urllib.request Python 3.0 or later\n",
      "[2021-08-06T15:08:57.597020] Start fetching snapshots.\n",
      "[2021-08-06T15:08:57.597042] Start fetching snapshot.\n",
      "[2021-08-06T15:08:57.597066] Retrieving project from snapshot: 58ac17bd-c357-4102-9f64-20cbb523ef6c\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 52\n",
      "[2021-08-06T15:08:57.893537] Finished fetching snapshot.\n",
      "[2021-08-06T15:08:57.893583] Start fetching snapshot.\n",
      "[2021-08-06T15:08:57.893678] Retrieving project from snapshot: a35dae47-0af9-46e3-88f7-36e57f963833\n",
      "[2021-08-06T15:09:06.322246] Finished fetching snapshot.\n",
      "[2021-08-06T15:09:06.322277] Finished fetching snapshots.\n",
      "[2021-08-06T15:09:06.322287] Finished extract_project.\n",
      "[2021-08-06T15:09:06.322386] Finished fetching and extracting the control code.\n",
      "[2021-08-06T15:09:06.328692] Start run_history_prep.\n",
      "[2021-08-06T15:09:06.334698] Job preparation is complete.\n",
      "[2021-08-06T15:09:06.334918] Entering Data Context Managers in Sidecar\n",
      "[2021-08-06T15:09:06.335558] Running Sidecar prep cmd...\n",
      "[2021-08-06T15:09:06.633979] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/77445767-8428-4d32-8141-4082802d063a/wd/azureml/77445767-8428-4d32-8141-4082802d063a\n",
      "[2021-08-06T15:09:06.634695] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.32.0 azureml-dataprep==2.20.1. Session id: f8968838-6714-4abe-ad13-361a6514af41. Run id: 77445767-8428-4d32-8141-4082802d063a.\n",
      "Processing 'capstone_inferences'.\n",
      "Mode: 'mount'.\n",
      "Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/77445767-8428-4d32-8141-4082802d063a/wd/capstone_inferences_workspaceblobstore'.\n",
      "Mounted capstone_inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/77445767-8428-4d32-8141-4082802d063a/wd/capstone_inferences_workspaceblobstore.\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Set OutputDataset capstone_inferences's target path to /tmp/77ed2d3f-0758-4012-b087-e219e706c71d\n",
      "[2021-08-06T15:09:16.916829] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2021-08-06T15:09:17.406939] Ran Sidecar prep cmd.\n",
      "[2021-08-06T15:09:17.407047] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/08/06 15:09:51 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/08/06 15:09:51 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/06 15:09:51 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "2021/08/06 15:09:51 Send process info logs to master server succeeded\n",
      "2021/08/06 15:09:51 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "2021/08/06 15:09:51 Send process info logs to master server succeeded\n",
      "[2021-08-06T15:09:51.165750] Entering context manager injector.\n",
      "[2021-08-06T15:09:51.551388] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.33.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:capstone_inferences', '--input_ds_0', 'daily_load_data'])\n",
      "Script type = None\n",
      "[2021-08-06T15:09:51.555685] Entering Run History Context Manager.\n",
      "[2021-08-06T15:09:52.217591] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/77445767-8428-4d32-8141-4082802d063a/wd/azureml/77445767-8428-4d32-8141-4082802d063a\n",
      "[2021-08-06T15:09:52.217812] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.33.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$capstone_inferences', '--input_ds_0', 'daily_load_data']\n",
      "[2021-08-06T15:09:52.217838] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.33.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/tmp/77ed2d3f-0758-4012-b087-e219e706c71d', '--input_ds_0', 'daily_load_data']\n",
      "\n",
      "2021/08/06 15:09:56 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import shutil\r\n",
    "\r\n",
    "# Remove the local results folder if left over from a previous run\r\n",
    "shutil.rmtree('capstone-batch-results', ignore_errors=True)\r\n",
    "\r\n",
    "# Get the run for the first step and download its output\r\n",
    "prediction_run = next(pipeline_run.get_children())\r\n",
    "prediction_output = prediction_run.get_output_data('capstone_inferences')\r\n",
    "prediction_output.download(local_path='capstone-batch-results')\r\n",
    "\r\n",
    "# Traverse the folder hierarchy and find the results file\r\n",
    "for root, dirs, files in os.walk('capstone-batch-results'):\r\n",
    "    for file in files:\r\n",
    "        if file.endswith('parallel_run_step.txt'):\r\n",
    "            result_file = os.path.join(root,file)\r\n",
    "\r\n",
    "# cleanup output format\r\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
    "df.columns = [\"File\", \"Prediction\"]\r\n",
    "\r\n",
    "# Display the first 20 results\r\n",
    "df.head(20)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('capstone_mlops': conda)"
  },
  "interpreter": {
   "hash": "262afc0293dc3ae75c593851c5492fec85b6d8ae246ad1202c627cb3da9b24dc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}